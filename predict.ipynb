{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "############ load and digitize the data\n",
    "data=pd.read_csv('/home/ebotian/MCM/tennis.csv')\n",
    "data = pd.get_dummies(data, columns=['winner_shot_type','serve_width','serve_depth','return_depth'])\n",
    "############\n",
    "\n",
    "############# pre-process the data\n",
    "# fill nan with 0, and replace AD with 50\n",
    "data = data.fillna(0)\n",
    "data = data.replace('AD', 50.0)\n",
    "data['point_victor']=data[\"point_victor\"].replace(2,0)\n",
    "#print(data.iloc[:,15])\n",
    "\n",
    "# split the data into different match\n",
    "grouped = dict(tuple(data.groupby(data['match_id'].ne(data['match_id'].shift()).cumsum())))\n",
    "\n",
    "# Rename the subdata\n",
    "subdata = {df['match_id'].iloc[0]: df for _, df in grouped.items()}\n",
    "\n",
    "# Create a new dataset from the first column, excluding duplicates\n",
    "match = pd.DataFrame(data.iloc[:, 0].drop_duplicates()).iloc[:,0].tolist()\n",
    "#print(match_id[0])\n",
    "##############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the id of the match\n",
    "id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average interval (excluding top 5% and bottom 5%): 0 days 00:00:43.784090909\n"
     ]
    }
   ],
   "source": [
    "# Calculate the time difference between consecutive rows\n",
    "\n",
    "# Convert the timestamp column to datetime format\n",
    "subdata[match[id]]['elapsed_time'] = pd.to_timedelta(subdata[match[id]]['elapsed_time'])\n",
    "\n",
    "# Calculate the time difference between consecutive rows\n",
    "subdata[match[id]]['time_diff'] = subdata[match[id]]['elapsed_time'].diff()\n",
    "\n",
    "# Calculate the 5th and 95th percentiles\n",
    "lower_threshold = subdata[match[id]]['time_diff'].quantile(0.05)\n",
    "upper_threshold = subdata[match[id]]['time_diff'].quantile(0.95)\n",
    "\n",
    "# Exclude the top 5% and bottom 5% of periods\n",
    "filtered_diff = subdata[match[id]]['time_diff'][(subdata[match[id]]['time_diff'] > lower_threshold) & (subdata[match[id]]['time_diff'] < upper_threshold)]\n",
    "\n",
    "# Calculate the average of the remaining intervals\n",
    "average_interval = filtered_diff.mean()\n",
    "\n",
    "print(f'Average interval (excluding top 5% and bottom 5%): {average_interval}')\n",
    "\n",
    "# Convert the time differences to integer seconds\n",
    "subdata[match[id]]['time_diff'] = subdata[match[id]]['time_diff'].dt.total_seconds()\n",
    "\n",
    "# Replace 'NaT' values with 0\n",
    "subdata[match[id]]['time_diff'] = subdata[match[id]]['time_diff'].fillna(0).astype(int)\n",
    "#fill nan with 0\n",
    "#subdata[match[id]]['time_diff'] = subdata[match[id]]['time_diff'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ add features\n",
    "add_feature=[\"score_diff\"]\n",
    "\n",
    "########## defining the new features\n",
    "\n",
    "#subdata[match_id[0]][add_feature[0]] = subdata[match_id[0]]['p1_games'] - subdata[match_id[0]]['p2_games']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target\n",
    "target=pd.DataFrame(subdata[match[id]][\"point_victor\"])\n",
    "# Add the \"elapsed_time\" column to the \"target\" DataFrame\n",
    "target.insert(0, 'elapsed_time', subdata[match[id]]['elapsed_time'])\n",
    "target['elapsed_time'] = target['elapsed_time'].dt.total_seconds()\n",
    "\n",
    "subdata[match[id]]=subdata[match[id]].drop(columns=[\"point_victor\"])\n",
    "features=subdata[match[id]].iloc[:,4:]\n",
    "#print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'target' is your time series data...\n",
    "\n",
    "# Split data into training set and test set\n",
    "train_size = int(len(target) * 0.7)\n",
    "train, test = target[0:train_size], target[train_size:len(target)]\n",
    "train=train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5253652185900073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ARIMA\n",
    "model_arima = ARIMA(train[\"point_victor\"], order=(5,1,0))\n",
    "model_arima_fit = model_arima.fit()\n",
    "forecast_output = model_arima_fit.forecast(steps=len(test))\n",
    "#print(forecast_output)\n",
    "#print(test)\n",
    "rmse_arima = sqrt(mean_squared_error(test[\"point_victor\"], forecast_output))\n",
    "print(rmse_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49952779636230954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SARIMA\n",
    "model_sarima = SARIMAX(train[\"point_victor\"], order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "model_sarima_fit = model_sarima.fit(disp=0)\n",
    "predictions_sarima = model_sarima_fit.forecast(steps=len(test))\n",
    "rmse_sarima = sqrt(mean_squared_error(test[\"point_victor\"], predictions_sarima))\n",
    "print(rmse_sarima)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7feb9a86e520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "[[[ 9989.]]\n",
      "\n",
      " [[10157.]]\n",
      "\n",
      " [[10203.]]\n",
      "\n",
      " [[10248.]]\n",
      "\n",
      " [[10272.]]\n",
      "\n",
      " [[10300.]]\n",
      "\n",
      " [[10355.]]\n",
      "\n",
      " [[10390.]]\n",
      "\n",
      " [[10443.]]\n",
      "\n",
      " [[10483.]]\n",
      "\n",
      " [[10510.]]\n",
      "\n",
      " [[10553.]]\n",
      "\n",
      " [[10629.]]\n",
      "\n",
      " [[10666.]]\n",
      "\n",
      " [[10712.]]\n",
      "\n",
      " [[10755.]]\n",
      "\n",
      " [[10788.]]\n",
      "\n",
      " [[10840.]]\n",
      "\n",
      " [[10907.]]\n",
      "\n",
      " [[10945.]]\n",
      "\n",
      " [[11007.]]\n",
      "\n",
      " [[11046.]]\n",
      "\n",
      " [[11104.]]\n",
      "\n",
      " [[11136.]]\n",
      "\n",
      " [[11176.]]\n",
      "\n",
      " [[11229.]]\n",
      "\n",
      " [[11258.]]\n",
      "\n",
      " [[11342.]]\n",
      "\n",
      " [[11395.]]\n",
      "\n",
      " [[11427.]]\n",
      "\n",
      " [[11554.]]\n",
      "\n",
      " [[11571.]]\n",
      "\n",
      " [[11592.]]\n",
      "\n",
      " [[11627.]]\n",
      "\n",
      " [[11647.]]\n",
      "\n",
      " [[11684.]]\n",
      "\n",
      " [[11712.]]\n",
      "\n",
      " [[11753.]]\n",
      "\n",
      " [[11818.]]\n",
      "\n",
      " [[11842.]]\n",
      "\n",
      " [[11875.]]\n",
      "\n",
      " [[11924.]]\n",
      "\n",
      " [[11953.]]\n",
      "\n",
      " [[11986.]]\n",
      "\n",
      " [[12021.]]\n",
      "\n",
      " [[12054.]]\n",
      "\n",
      " [[12178.]]\n",
      "\n",
      " [[12235.]]\n",
      "\n",
      " [[12303.]]\n",
      "\n",
      " [[12328.]]\n",
      "\n",
      " [[12364.]]\n",
      "\n",
      " [[12422.]]\n",
      "\n",
      " [[12488.]]\n",
      "\n",
      " [[12536.]]\n",
      "\n",
      " [[12561.]]\n",
      "\n",
      " [[12594.]]\n",
      "\n",
      " [[12631.]]\n",
      "\n",
      " [[12747.]]\n",
      "\n",
      " [[12781.]]\n",
      "\n",
      " [[12825.]]\n",
      "\n",
      " [[12864.]]\n",
      "\n",
      " [[12893.]]\n",
      "\n",
      " [[12932.]]\n",
      "\n",
      " [[12954.]]\n",
      "\n",
      " [[12986.]]\n",
      "\n",
      " [[13012.]]\n",
      "\n",
      " [[13041.]]\n",
      "\n",
      " [[13172.]]\n",
      "\n",
      " [[13214.]]\n",
      "\n",
      " [[13260.]]\n",
      "\n",
      " [[13292.]]\n",
      "\n",
      " [[13336.]]\n",
      "\n",
      " [[13368.]]\n",
      "\n",
      " [[13429.]]\n",
      "\n",
      " [[13463.]]\n",
      "\n",
      " [[13510.]]\n",
      "\n",
      " [[13548.]]\n",
      "\n",
      " [[13588.]]\n",
      "\n",
      " [[13635.]]\n",
      "\n",
      " [[13671.]]\n",
      "\n",
      " [[13738.]]\n",
      "\n",
      " [[13855.]]\n",
      "\n",
      " [[13912.]]\n",
      "\n",
      " [[13950.]]\n",
      "\n",
      " [[14005.]]\n",
      "\n",
      " [[14041.]]\n",
      "\n",
      " [[14102.]]\n",
      "\n",
      " [[14134.]]\n",
      "\n",
      " [[14171.]]]\n",
      "[[0.8203124 ]\n",
      " [0.83468616]\n",
      " [0.8385924 ]\n",
      " [0.8424529 ]\n",
      " [0.84446704]\n",
      " [0.84693897]\n",
      " [0.85160816]\n",
      " [0.85461414]\n",
      " [0.8591002 ]\n",
      " [0.86253345]\n",
      " [0.86482227]\n",
      " [0.86853015]\n",
      " [0.8749999 ]\n",
      " [0.8781432 ]\n",
      " [0.88212574]\n",
      " [0.8858031 ]\n",
      " [0.8886107 ]\n",
      " [0.893051  ]\n",
      " [0.8987578 ]\n",
      " [0.9020232 ]\n",
      " [0.90730274]\n",
      " [0.91062915]\n",
      " [0.915573  ]\n",
      " [0.9183196 ]\n",
      " [0.92176807]\n",
      " [0.92625415]\n",
      " [0.9287566 ]\n",
      " [0.9359282 ]\n",
      " [0.9404143 ]\n",
      " [0.9431914 ]\n",
      " [0.95399463]\n",
      " [0.9554595 ]\n",
      " [0.9572295 ]\n",
      " [0.9602202 ]\n",
      " [0.9619292 ]\n",
      " [0.96510303]\n",
      " [0.9676055 ]\n",
      " [0.9709929 ]\n",
      " [0.9765471 ]\n",
      " [0.9785918 ]\n",
      " [0.98142993]\n",
      " [0.9855803 ]\n",
      " [0.98808277]\n",
      " [0.9909514 ]\n",
      " [0.9939116 ]\n",
      " [0.99671924]\n",
      " [1.0073088 ]\n",
      " [1.0121306 ]\n",
      " [1.0180205 ]\n",
      " [1.0201567 ]\n",
      " [1.023178  ]\n",
      " [1.0281523 ]\n",
      " [1.0337981 ]\n",
      " [1.0378875 ]\n",
      " [1.0399932 ]\n",
      " [1.0427703 ]\n",
      " [1.0460356 ]\n",
      " [1.0558928 ]\n",
      " [1.0588835 ]\n",
      " [1.0625762 ]\n",
      " [1.0659026 ]\n",
      " [1.0684355 ]\n",
      " [1.071762  ]\n",
      " [1.073654  ]\n",
      " [1.0763091 ]\n",
      " [1.0785674 ]\n",
      " [1.0810088 ]\n",
      " [1.0921782 ]\n",
      " [1.0957488 ]\n",
      " [1.0997161 ]\n",
      " [1.1025237 ]\n",
      " [1.1062163 ]\n",
      " [1.1090239 ]\n",
      " [1.114273  ]\n",
      " [1.1171721 ]\n",
      " [1.1210479 ]\n",
      " [1.1243743 ]\n",
      " [1.1277312 ]\n",
      " [1.13179   ]\n",
      " [1.1349028 ]\n",
      " [1.1405791 ]\n",
      " [1.1504973 ]\n",
      " [1.1554412 ]\n",
      " [1.1586455 ]\n",
      " [1.1633452 ]\n",
      " [1.166397  ]\n",
      " [1.171585  ]\n",
      " [1.1743926 ]\n",
      " [1.1775664 ]]\n",
      "0.6819136502364613\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "from re import X\n",
    "\n",
    "\n",
    "X_train = np.array([[train[\"elapsed_time\"].values[i]] for i in range(1, len(train))])\n",
    "y_train = np.array([train[\"point_victor\"].values[i] for i in range(1, len(train))])\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "model_lstm.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "X_test = np.array([[test[\"elapsed_time\"].values[i]] for i in range(1, len(test))])\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "predictions_lstm = model_lstm.predict(X_test)\n",
    "print(X_test)\n",
    "print(predictions_lstm)\n",
    "rmse_lstm = sqrt(mean_squared_error(test[\"point_victor\"][1:], predictions_lstm))\n",
    "print(rmse_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210]\n",
      " [211]\n",
      " [212]\n",
      " [213]\n",
      " [214]\n",
      " [215]\n",
      " [216]\n",
      " [217]\n",
      " [218]\n",
      " [219]\n",
      " [220]\n",
      " [221]\n",
      " [222]\n",
      " [223]\n",
      " [224]\n",
      " [225]\n",
      " [226]\n",
      " [227]\n",
      " [228]\n",
      " [229]\n",
      " [230]\n",
      " [231]\n",
      " [232]\n",
      " [233]\n",
      " [234]\n",
      " [235]\n",
      " [236]\n",
      " [237]\n",
      " [238]\n",
      " [239]\n",
      " [240]\n",
      " [241]\n",
      " [242]\n",
      " [243]\n",
      " [244]\n",
      " [245]\n",
      " [246]\n",
      " [247]\n",
      " [248]\n",
      " [249]\n",
      " [250]\n",
      " [251]\n",
      " [252]\n",
      " [253]\n",
      " [254]\n",
      " [255]\n",
      " [256]\n",
      " [257]\n",
      " [258]\n",
      " [259]\n",
      " [260]\n",
      " [261]\n",
      " [262]\n",
      " [263]\n",
      " [264]\n",
      " [265]\n",
      " [266]\n",
      " [267]\n",
      " [268]\n",
      " [269]\n",
      " [270]\n",
      " [271]\n",
      " [272]\n",
      " [273]\n",
      " [274]\n",
      " [275]\n",
      " [276]\n",
      " [277]\n",
      " [278]\n",
      " [279]\n",
      " [280]\n",
      " [281]\n",
      " [282]\n",
      " [283]\n",
      " [284]\n",
      " [285]\n",
      " [286]\n",
      " [287]\n",
      " [288]\n",
      " [289]\n",
      " [290]\n",
      " [291]\n",
      " [292]\n",
      " [293]\n",
      " [294]\n",
      " [295]\n",
      " [296]\n",
      " [297]\n",
      " [298]\n",
      " [299]]\n",
      "RMSE values:\n",
      "ARIMA:  0.5253652185900073\n",
      "SARIMA:  0.49952779636230954\n",
      "LSTM:  0.17932097083592433\n",
      "Linear Regression:  63.11021858487515\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Linear Regression\n",
    "from re import X\n",
    "\n",
    "\n",
    "X_train = np.array([i for i in range(0, len(train))]).reshape(-1, 1)\n",
    "y_train = train.values\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "X_test = np.array([i for i in range(len(train), len(train) + len(test))]).reshape(-1, 1)\n",
    "predictions_linear = model_linear.predict(X_test)\n",
    "rmse_linear = sqrt(mean_squared_error(test, predictions_linear))\n",
    "\n",
    "print(X_test)\n",
    "\n",
    "# Print RMSE values\n",
    "print('RMSE values:')\n",
    "print('ARIMA: ', rmse_arima)\n",
    "print('SARIMA: ', rmse_sarima)\n",
    "print('LSTM: ', rmse_lstm)\n",
    "print('Linear Regression: ', rmse_linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
